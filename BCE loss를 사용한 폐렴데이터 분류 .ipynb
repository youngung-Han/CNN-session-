{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nfrom torch import nn\n!pip install torchinfo\nfrom torchinfo import summary\nfrom torch.nn import functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T12:31:15.681662Z","iopub.execute_input":"2021-08-24T12:31:15.682051Z","iopub.status.idle":"2021-08-24T12:31:24.045929Z","shell.execute_reply.started":"2021-08-24T12:31:15.681969Z","shell.execute_reply":"2021-08-24T12:31:24.045021Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchinfo\n  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\nInstalling collected packages: torchinfo\nSuccessfully installed torchinfo-1.5.3\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 하이퍼 파라미터 정의 ","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.001\nmomentum = 0.9\ntraining_epochs = 20\nbatch_size = 100\ntorch.manual_seed(2018171013)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:31:41.024342Z","iopub.execute_input":"2021-08-24T12:31:41.024707Z","iopub.status.idle":"2021-08-24T12:31:41.038338Z","shell.execute_reply.started":"2021-08-24T12:31:41.024669Z","shell.execute_reply":"2021-08-24T12:31:41.037209Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f7a9c019d90>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 데이터 가져오기 ","metadata":{}},{"cell_type":"code","source":"transforms_train = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    #transforms.RandomHorizontalFlip(p=0.5),\n    #transforms.RandomVerticalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485, 0.456, 0.406],\n        [0.229, 0.224, 0.225]\n    )\n])\n\ntransforms_test = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485, 0.456, 0.406],\n        [0.229, 0.224, 0.225]\n    )\n])\ntrainset = torchvision.datasets.ImageFolder(root=\"../input/chest-xray-pneumonia/chest_xray/train\", transform=transforms_train)\ntestset = torchvision.datasets.ImageFolder(root=\"../input/chest-xray-pneumonia/chest_xray/test\", transform=transforms_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:31:45.053934Z","iopub.execute_input":"2021-08-24T12:31:45.054260Z","iopub.status.idle":"2021-08-24T12:31:49.801195Z","shell.execute_reply.started":"2021-08-24T12:31:45.054231Z","shell.execute_reply":"2021-08-24T12:31:49.800362Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 로더","metadata":{}},{"cell_type":"code","source":"trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:31:53.900143Z","iopub.execute_input":"2021-08-24T12:31:53.900468Z","iopub.status.idle":"2021-08-24T12:31:53.905209Z","shell.execute_reply.started":"2021-08-24T12:31:53.900438Z","shell.execute_reply":"2021-08-24T12:31:53.903856Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 체크 ","metadata":{}},{"cell_type":"code","source":"print(trainset.__getitem__(0)[0].size(), trainset.__len__())\nprint(testset.__getitem__(0)[0].size(), testset.__len__())\n\nprint(len(trainset),len(testset))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:31:56.870168Z","iopub.execute_input":"2021-08-24T12:31:56.870520Z","iopub.status.idle":"2021-08-24T12:31:57.097708Z","shell.execute_reply.started":"2021-08-24T12:31:56.870488Z","shell.execute_reply":"2021-08-24T12:31:57.096296Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"torch.Size([3, 224, 224]) 5216\ntorch.Size([3, 224, 224]) 624\n5216 624\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 모델 정의 ","metadata":{}},{"cell_type":"code","source":"#모델을 정의할 때 유념해야할 건 각 층의 결과물의 사이즈입니다. \n#이 층에서 어떤 size를 가진 데이터를 몇 개 도출하는지 정확하게 알고 있어야 정확한 모델을 정의할 수 있습니다. \n#모델이 복잡해지면 복잡해질수록 이는 더욱 중요해집니다. 때문에 모델을 정의할 때 옆에 각 모델이 도출하는 데이터의 크기를 써넣는 것을 추천드립니다. \n#해당 모델은 임의로 만든 모델입니다. 이 모델이 다른 모델보다 뛰어나다는 보장이 없습니다. \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()           \n        self.layer = nn.Sequential(                                             \n            nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5),             # [batch_size,3,224,224] -> [batch_size,16,220,220]\n            nn.ReLU(),                                                          \n            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),            #  [batch_size,32,216,216]\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2),                               # [batch_size,32,108,108] \n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),          # [batch_size,64,104,104] \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2)                                # [batch_size,64,52,52] \n        )\n        self.fc_layer = nn.Sequential(                                          \n            nn.Linear(64*52*52,100),             #Linear(64*52*52,100)                                   # [batch_size,64*52*52] -> [batch_size,100]\n            nn.ReLU(),\n            nn.Linear(100,1)                                                   # [batch_size,100] -> [batch_size,1]\n        )       \n        \n    def forward(self,x):\n        out = self.layer(x)                                                     # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행합니다.\n        out = out.view(-1,64*52*52)                                               # view 함수를 이용해 텐서의 형태를 [batch_size,나머지]로 바꿔줍니다. \n                                                                                # ex) 2x3 형태였던 텐서를 .view(1,-1) 해주면 1x6의 형태로 바뀝니다. .view(3,-1)이면 3x2로 바뀜.\n                                                                                # 만약 전체 텐서의 크기가 batch_size로 나누어 떨어지지 않으면 오류가 납니다.\n        out = self.fc_layer(out)\n    \n        return torch.sigmoid(out)\n\n\n# https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d\n# https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nModel = CNN().to(device)\nprint(summary(Model, input_size=(1, 3, 224, 224), verbose=0))\n\n  ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:32:01.169657Z","iopub.execute_input":"2021-08-24T12:32:01.170015Z","iopub.status.idle":"2021-08-24T12:32:06.170755Z","shell.execute_reply.started":"2021-08-24T12:32:01.169980Z","shell.execute_reply":"2021-08-24T12:32:06.169916Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nCNN                                      --                        --\n├─Sequential: 1-1                        [1, 64, 52, 52]           --\n│    └─Conv2d: 2-1                       [1, 16, 220, 220]         1,216\n│    └─ReLU: 2-2                         [1, 16, 220, 220]         --\n│    └─Conv2d: 2-3                       [1, 32, 216, 216]         12,832\n│    └─ReLU: 2-4                         [1, 32, 216, 216]         --\n│    └─MaxPool2d: 2-5                    [1, 32, 108, 108]         --\n│    └─Conv2d: 2-6                       [1, 64, 104, 104]         51,264\n│    └─ReLU: 2-7                         [1, 64, 104, 104]         --\n│    └─MaxPool2d: 2-8                    [1, 64, 52, 52]           --\n├─Sequential: 1-2                        [1, 1]                    --\n│    └─Linear: 2-9                       [1, 100]                  17,305,700\n│    └─ReLU: 2-10                        [1, 100]                  --\n│    └─Linear: 2-11                      [1, 1]                    101\n==========================================================================================\nTotal params: 17,371,113\nTrainable params: 17,371,113\nNon-trainable params: 0\nTotal mult-adds (G): 1.23\n==========================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 23.68\nParams size (MB): 69.48\nEstimated Total Size (MB): 93.76\n==========================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Loss ,optim 정의 ","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(Model.parameters(), momentum=momentum, lr=learning_rate)\n\ntotal_data = len(trainset) # 5216 \niteration_num = len(trainloader)\n\nprint(\"LEARNING STARTS! (model: My CNN model)\")\nprint(\"total data is \", total_data)\nprint(\"there will be about \", iteration_num, \"steps\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:32:12.229963Z","iopub.execute_input":"2021-08-24T12:32:12.230316Z","iopub.status.idle":"2021-08-24T12:32:12.239707Z","shell.execute_reply.started":"2021-08-24T12:32:12.230287Z","shell.execute_reply":"2021-08-24T12:32:12.238665Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"LEARNING STARTS! (model: My CNN model)\ntotal data is  5216\nthere will be about  53 steps\n","output_type":"stream"}]},{"cell_type":"markdown","source":"학습 ,테스팅 ","metadata":{}},{"cell_type":"code","source":"current_accuracy = 0\nfor epoch in range(training_epochs):\n    \n    avg_cost = 0\n    step = 0\n    for X, Y in trainloader:\n        X = X.to(device)\n        Y =Y.view(-1,1)\n        Y =Y.to(torch.float32)\n        Y =Y.to(device)\n        optimizer.zero_grad()\n        hypothesis = Model(X)\n        \n        cost = criterion(hypothesis, Y)\n        cost.backward()\n        optimizer.step()\n        avg_cost += cost / iteration_num\n        if(step % 100 == 0):\n            print(\"STEP [\", step, \"/\", iteration_num, \"] LOSS: \", cost.item())\n        step += 1\n    print('[EPOCH: {:>4}] COST = {:>.9}'.format(epoch + 1, avg_cost))\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in testloader:\n            outputs = Model(images.to(device))\n            total += labels.size(0)\n            #correct_prediction = torch.argmax(outputs.data, 1) == labels.to(device)\n            correct_prediction = outputs[outputs.data>0.5]\n            correct += correct_prediction.sum()\n\n        accuracy = int(correct) / total\n        print('EPOCH', epoch+1,  ' ACCURACY:', accuracy)\n        if(accuracy > current_accuracy):\n            print('IMPROVEMENT WAS THERE. SAVE CKPT...')\n            current_accuracy = accuracy\nprint(\"LEARNING FINISHED! (model: my CNN model)\")\nprint('FINAL ACCURACY: ', current_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:32:15.221918Z","iopub.execute_input":"2021-08-24T12:32:15.222322Z","iopub.status.idle":"2021-08-24T12:40:22.763728Z","shell.execute_reply.started":"2021-08-24T12:32:15.222281Z","shell.execute_reply":"2021-08-24T12:40:22.761414Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"STEP [ 0 / 53 ] LOSS:  0.6889982223510742\n[EPOCH:    1] COST = 0.535172105\nEPOCH 1  ACCURACY: 0.6506410256410257\nIMPROVEMENT WAS THERE. SAVE CKPT...\nSTEP [ 0 / 53 ] LOSS:  0.327687531709671\n[EPOCH:    2] COST = 0.194589764\nEPOCH 2  ACCURACY: 0.8525641025641025\nIMPROVEMENT WAS THERE. SAVE CKPT...\nSTEP [ 0 / 53 ] LOSS:  0.25135231018066406\n[EPOCH:    3] COST = 0.15045616\nEPOCH 3  ACCURACY: 0.7211538461538461\nSTEP [ 0 / 53 ] LOSS:  0.23080185055732727\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-341258d70747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mavg_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0moh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1941\u001b[0m                 )\n\u001b[1;32m   1942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1943\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:49:28.012759Z","iopub.execute_input":"2021-08-21T06:49:28.013213Z","iopub.status.idle":"2021-08-21T06:49:28.021183Z","shell.execute_reply.started":"2021-08-21T06:49:28.013168Z","shell.execute_reply":"2021-08-21T06:49:28.020234Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['NORMAL', 'PNEUMONIA']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:44:16.860078Z","iopub.execute_input":"2021-08-21T06:44:16.860405Z","iopub.status.idle":"2021-08-21T06:44:16.867683Z","shell.execute_reply.started":"2021-08-21T06:44:16.860370Z","shell.execute_reply":"2021-08-21T06:44:16.866688Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터 비교 ","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:51:20.047470Z","iopub.execute_input":"2021-08-21T06:51:20.047794Z","iopub.status.idle":"2021-08-21T06:51:20.054102Z","shell.execute_reply.started":"2021-08-21T06:51:20.047764Z","shell.execute_reply":"2021-08-21T06:51:20.053337Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:56:39.395847Z","iopub.execute_input":"2021-08-21T06:56:39.396204Z","iopub.status.idle":"2021-08-21T06:56:39.402019Z","shell.execute_reply.started":"2021-08-21T06:56:39.396170Z","shell.execute_reply":"2021-08-21T06:56:39.400906Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:55:47.643792Z","iopub.execute_input":"2021-08-21T06:55:47.644148Z","iopub.status.idle":"2021-08-21T06:55:47.653659Z","shell.execute_reply.started":"2021-08-21T06:55:47.644096Z","shell.execute_reply":"2021-08-21T06:55:47.652840Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:56:13.640377Z","iopub.execute_input":"2021-08-21T06:56:13.640700Z","iopub.status.idle":"2021-08-21T06:56:13.795954Z","shell.execute_reply.started":"2021-08-21T06:56:13.640669Z","shell.execute_reply":"2021-08-21T06:56:13.795049Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:12:21.37468Z","iopub.execute_input":"2021-08-21T06:12:21.375084Z","iopub.status.idle":"2021-08-21T06:12:21.379351Z","shell.execute_reply.started":"2021-08-21T06:12:21.375045Z","shell.execute_reply":"2021-08-21T06:12:21.378345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-21T06:57:40.546185Z","iopub.execute_input":"2021-08-21T06:57:40.546514Z","iopub.status.idle":"2021-08-21T06:57:40.550292Z","shell.execute_reply.started":"2021-08-21T06:57:40.546483Z","shell.execute_reply":"2021-08-21T06:57:40.549239Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}